[2025-02-20T10:18:31.340+0100] {processor.py:186} INFO - Started process (PID=5359) to work on /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.341+0100] {processor.py:914} INFO - Processing file /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:18:31.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.342+0100] {dagbag.py:588} INFO - Filling up the DagBag from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.436+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.436+0100] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2025-02-20T10:18:31.533+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.645+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.644+0100] {override.py:1912} INFO - Created Permission View: can delete on DAG:example_workday_timetable
[2025-02-20T10:18:31.648+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.648+0100] {override.py:1912} INFO - Created Permission View: can edit on DAG:example_workday_timetable
[2025-02-20T10:18:31.651+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.651+0100] {override.py:1912} INFO - Created Permission View: can read on DAG:example_workday_timetable
[2025-02-20T10:18:31.654+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.654+0100] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.656+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.656+0100] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.658+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.657+0100] {override.py:1912} INFO - Created Permission View: can create on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.660+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.660+0100] {override.py:1912} INFO - Created Permission View: can read on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.660+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.660+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:18:31.664+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.664+0100] {dag.py:3262} INFO - Creating ORM DAG for example_workday_timetable
[2025-02-20T10:18:31.686+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.686+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-02-20T10:18:31.694+0100] {processor.py:208} INFO - Processing /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py took 0.355 seconds
[2025-02-20T10:49:04.448+0100] {processor.py:186} INFO - Started process (PID=5990) to work on /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.448+0100] {processor.py:914} INFO - Processing file /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:49:04.449+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.449+0100] {dagbag.py:588} INFO - Filling up the DagBag from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.531+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.531+0100] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2025-02-20T10:49:04.617+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.702+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.701+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:49:04.725+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.725+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-02-20T10:49:04.732+0100] {processor.py:208} INFO - Processing /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py took 0.285 seconds
[2025-02-20T10:52:09.612+0100] {processor.py:186} INFO - Started process (PID=6204) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.613+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:52:09.613+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.613+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.615+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.615+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:52:09.617+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.685+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:52:09.731+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.730+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:52:09.740+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.739+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:52:09.748+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.138 seconds
[2025-02-20T10:54:00.106+0100] {processor.py:186} INFO - Started process (PID=6464) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.107+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:54:00.107+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.107+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.109+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.109+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:54:00.112+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.174+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.174+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:54:00.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.182+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:54:00.189+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.189+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:54:00.196+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T10:55:15.824+0100] {processor.py:186} INFO - Started process (PID=6659) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.825+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:55:15.825+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.825+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.827+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.827+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:55:15.830+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.894+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.894+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:55:15.902+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.902+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:55:15.908+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.908+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:55:15.916+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T10:56:27.948+0100] {processor.py:186} INFO - Started process (PID=6782) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:27.948+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:56:27.949+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:27.949+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:27.951+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:27.951+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:56:27.953+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:28.014+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.014+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:56:28.022+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.022+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:56:28.028+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.028+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:56:28.035+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T10:57:55.649+0100] {processor.py:186} INFO - Started process (PID=6928) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.649+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:57:55.650+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.650+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.653+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.653+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:57:55.657+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.721+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.720+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:57:55.728+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.728+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:57:55.735+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.735+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:57:55.742+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T10:59:21.334+0100] {processor.py:186} INFO - Started process (PID=7061) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.335+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:59:21.335+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.335+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.337+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:59:21.340+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.403+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.403+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:59:21.411+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.411+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:59:21.418+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.418+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:59:21.425+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:00:40.610+0100] {processor.py:186} INFO - Started process (PID=7269) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.611+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:00:40.612+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.611+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.613+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.613+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:00:40.615+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.677+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.677+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:00:40.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.685+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:00:40.691+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.691+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:00:40.698+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:01:52.466+0100] {processor.py:186} INFO - Started process (PID=7408) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.467+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:01:52.468+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.467+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.469+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.469+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:01:52.472+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.545+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.545+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:01:52.554+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.554+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:01:52.562+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.562+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:01:52.574+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.109 seconds
[2025-02-20T11:03:04.038+0100] {processor.py:186} INFO - Started process (PID=7548) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.039+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:03:04.040+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.039+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.042+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.041+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:03:04.044+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.116+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.114+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:03:04.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.181+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:03:04.254+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.254+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:03:04.276+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.239 seconds
[2025-02-20T11:04:14.070+0100] {processor.py:186} INFO - Started process (PID=7669) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.071+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:04:14.072+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.072+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.073+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.073+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:04:14.075+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.136+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.135+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:04:14.143+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.143+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:04:14.149+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.149+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:04:14.156+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:05:23.498+0100] {processor.py:186} INFO - Started process (PID=7827) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.499+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:05:23.499+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.499+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.501+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.501+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:05:23.503+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.564+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.564+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:05:23.572+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.572+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:05:23.579+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.579+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:05:23.586+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:06:33.872+0100] {processor.py:186} INFO - Started process (PID=8002) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.873+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:06:33.873+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.873+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.875+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.875+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:06:33.877+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.941+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.941+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:06:33.950+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.950+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:06:33.956+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.956+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:06:33.963+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:07:43.378+0100] {processor.py:186} INFO - Started process (PID=8147) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.378+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:07:43.379+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.379+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.381+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.380+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:07:43.383+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.444+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.444+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:07:43.452+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.452+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:07:43.458+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.458+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:07:43.465+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:08:52.830+0100] {processor.py:186} INFO - Started process (PID=8264) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.832+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:08:52.832+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.832+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.833+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.833+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:08:52.835+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.896+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.896+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:08:52.904+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.904+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:08:52.910+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.910+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:08:52.917+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:10:01.445+0100] {processor.py:186} INFO - Started process (PID=8370) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.445+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:10:01.446+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.446+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.447+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.447+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:10:01.449+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.511+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.511+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:10:01.519+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.519+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:10:01.525+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.525+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:10:01.532+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:11:13.350+0100] {processor.py:186} INFO - Started process (PID=8530) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.351+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:11:13.352+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.351+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.353+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:11:13.356+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.417+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.417+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:11:13.425+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.425+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:11:13.432+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.432+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:11:13.439+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:12:20.362+0100] {processor.py:186} INFO - Started process (PID=8623) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.363+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:12:20.363+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.363+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.365+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.365+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:12:20.368+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.428+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.427+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:12:20.435+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.435+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:12:20.442+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.442+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:12:20.448+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:13:29.324+0100] {processor.py:186} INFO - Started process (PID=8752) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.324+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:13:29.325+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.325+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.327+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.326+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:13:29.329+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.396+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.396+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:13:29.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.404+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:13:29.411+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.411+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:13:29.418+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T11:14:43.256+0100] {processor.py:186} INFO - Started process (PID=8885) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.257+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:14:43.257+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.257+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.259+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.259+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:14:43.261+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.322+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.322+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:14:43.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.330+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:14:43.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.337+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:14:43.346+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:15:56.316+0100] {processor.py:186} INFO - Started process (PID=8979) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.317+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:15:56.318+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.318+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.320+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.320+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:15:56.322+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.393+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.393+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:15:56.401+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.401+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:15:56.408+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.408+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:15:56.415+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T11:17:07.726+0100] {processor.py:186} INFO - Started process (PID=9181) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.727+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:17:07.727+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.727+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.729+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.729+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:17:07.732+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.793+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.793+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:17:07.801+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.800+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:17:07.807+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.807+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:17:07.814+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:18:20.720+0100] {processor.py:186} INFO - Started process (PID=9360) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.721+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:18:20.722+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.722+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.724+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.724+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:18:20.726+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.789+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.788+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:18:20.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.796+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:18:20.803+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.803+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:18:20.810+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:19:35.520+0100] {processor.py:186} INFO - Started process (PID=9549) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.520+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:19:35.521+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.521+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.522+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.522+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:19:35.524+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.587+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.587+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:19:35.595+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.595+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:19:35.601+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.601+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:19:35.608+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:20:49.838+0100] {processor.py:186} INFO - Started process (PID=9712) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.839+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:20:49.840+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.839+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.841+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.841+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:20:49.843+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.905+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.905+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:20:49.913+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.913+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:20:49.919+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.919+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:20:49.926+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:22:01.274+0100] {processor.py:186} INFO - Started process (PID=9810) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.275+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:22:01.275+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.275+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.277+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.277+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:22:01.279+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.341+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:22:01.350+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.350+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:22:01.357+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.357+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:22:01.365+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:23:16.482+0100] {processor.py:186} INFO - Started process (PID=9955) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.483+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:23:16.483+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.483+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.485+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.485+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:23:16.487+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.551+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.551+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:23:16.559+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.559+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:23:16.566+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.565+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:23:16.572+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:24:32.601+0100] {processor.py:186} INFO - Started process (PID=10094) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.602+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:24:32.603+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.603+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.604+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.604+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:24:32.607+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.669+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.669+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:24:32.677+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.677+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:24:32.683+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.683+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:24:32.689+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:25:46.273+0100] {processor.py:186} INFO - Started process (PID=10219) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.274+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:25:46.274+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.274+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.276+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.276+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:25:46.278+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.338+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.338+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:25:46.347+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.346+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:25:46.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.353+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:25:46.360+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:27:00.309+0100] {processor.py:186} INFO - Started process (PID=10395) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.310+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:27:00.310+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.310+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.312+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.312+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:27:00.314+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.375+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.375+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:27:00.383+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.382+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:27:00.389+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.389+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:27:00.396+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:28:14.790+0100] {processor.py:186} INFO - Started process (PID=10549) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.790+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:28:14.791+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.791+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.793+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.793+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:28:14.795+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.855+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.855+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:28:14.863+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.863+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:28:14.870+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.870+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:28:14.877+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:29:30.153+0100] {processor.py:186} INFO - Started process (PID=10762) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.154+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:29:30.154+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.154+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.156+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.156+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:29:30.158+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.220+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.220+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:29:30.228+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.228+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:29:30.234+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.234+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:29:30.242+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:30:43.312+0100] {processor.py:186} INFO - Started process (PID=10880) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.312+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:30:43.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.313+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.315+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.315+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:30:43.317+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.379+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.379+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:30:43.387+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.387+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:30:43.394+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.394+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:30:43.401+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T11:31:58.888+0100] {processor.py:186} INFO - Started process (PID=11018) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.889+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:31:58.889+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.889+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.891+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.891+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:31:58.893+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.953+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.953+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:31:58.964+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.964+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:31:58.970+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.970+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:31:58.977+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:33:10.468+0100] {processor.py:186} INFO - Started process (PID=11112) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.469+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:33:10.469+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.469+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.471+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.471+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:33:10.473+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.535+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.535+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:33:10.543+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.543+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:33:10.549+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.549+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:33:10.556+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:34:24.664+0100] {processor.py:186} INFO - Started process (PID=11233) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.665+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:34:24.665+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.665+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.667+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.667+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:34:24.670+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.732+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.732+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:34:24.740+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.740+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:34:24.746+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.746+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:34:24.753+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:35:37.965+0100] {processor.py:186} INFO - Started process (PID=11353) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:37.966+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:35:37.966+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:37.966+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:37.968+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:37.968+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:35:37.971+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:38.034+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.034+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:35:38.042+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.042+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:35:38.049+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.049+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:35:38.056+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:36:55.842+0100] {processor.py:186} INFO - Started process (PID=11517) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.843+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:36:55.844+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.844+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.845+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.845+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:36:55.847+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.911+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.911+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:36:55.919+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.919+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:36:55.925+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.925+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:36:55.932+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:38:12.757+0100] {processor.py:186} INFO - Started process (PID=11643) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.757+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:38:12.758+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.758+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.760+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.760+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:38:12.762+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.832+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.832+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:38:12.841+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.841+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:38:12.849+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.848+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:38:12.856+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T11:39:23.127+0100] {processor.py:186} INFO - Started process (PID=11744) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.128+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:39:23.128+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.128+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.130+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.130+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:39:23.132+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.193+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.193+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:39:23.201+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.201+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:39:23.207+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.207+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:39:23.214+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:40:36.067+0100] {processor.py:186} INFO - Started process (PID=11846) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.068+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:40:36.069+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.069+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.071+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.071+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:40:36.077+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.163+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.163+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:40:36.174+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.174+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:40:36.184+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.184+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:40:36.193+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.127 seconds
[2025-02-20T12:18:49.100+0100] {processor.py:186} INFO - Started process (PID=11984) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.100+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:18:49.101+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.101+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.102+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.102+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:18:49.105+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.170+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.170+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:18:49.178+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.178+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:18:49.185+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.185+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:18:49.192+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T12:20:31.138+0100] {processor.py:186} INFO - Started process (PID=12135) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.138+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:20:31.139+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.139+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.140+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.140+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:20:31.143+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.204+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.204+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:20:31.212+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.212+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:20:31.218+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.218+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:20:31.225+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T12:21:51.843+0100] {processor.py:186} INFO - Started process (PID=12248) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.844+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:21:51.844+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.844+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.846+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.846+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:21:51.848+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.908+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.908+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:21:51.916+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.916+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:21:51.923+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.923+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:21:51.930+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:23:10.018+0100] {processor.py:186} INFO - Started process (PID=12408) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.020+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:23:10.021+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.021+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.024+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.024+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:23:10.030+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.121+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.121+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:23:10.132+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.132+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:23:10.139+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.139+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:23:10.147+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.131 seconds
[2025-02-20T12:24:25.325+0100] {processor.py:186} INFO - Started process (PID=12546) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.326+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:24:25.326+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.326+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.328+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.328+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:24:25.331+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.396+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.396+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:24:25.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.404+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:24:25.410+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.410+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:24:25.417+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T12:25:38.232+0100] {processor.py:186} INFO - Started process (PID=12663) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.233+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:25:38.239+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.239+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.241+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.241+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:25:38.244+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.326+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.326+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:25:38.335+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.335+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:25:38.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.342+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:25:38.350+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.119 seconds
[2025-02-20T12:26:53.715+0100] {processor.py:186} INFO - Started process (PID=12839) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.715+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:26:53.716+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.716+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.718+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.718+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:26:53.720+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.782+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.782+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:26:53.790+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.790+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:26:53.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.796+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:26:53.803+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T12:28:09.522+0100] {processor.py:186} INFO - Started process (PID=12993) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.523+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:28:09.523+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.523+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.526+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.526+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:28:09.528+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.596+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.596+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:28:09.604+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.604+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:28:09.611+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.611+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:28:09.618+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.099 seconds
[2025-02-20T12:29:23.382+0100] {processor.py:186} INFO - Started process (PID=13133) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.383+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:29:23.383+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.383+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.385+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:29:23.387+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.456+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.456+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:29:23.464+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.464+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:29:23.471+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.471+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:29:23.478+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T12:30:34.756+0100] {processor.py:186} INFO - Started process (PID=13286) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.757+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:30:34.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.757+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.759+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.759+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:30:34.761+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.836+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.834+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:30:34.855+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.855+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:30:34.862+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.862+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:30:34.870+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.115 seconds
[2025-02-20T12:31:52.640+0100] {processor.py:186} INFO - Started process (PID=13466) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.641+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:31:52.641+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.641+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.643+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.643+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:31:52.645+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.706+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.706+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:31:52.715+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.714+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:31:52.721+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.721+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:31:52.728+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T12:33:11.521+0100] {processor.py:186} INFO - Started process (PID=13639) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.522+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:33:11.522+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.522+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.524+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.524+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:33:11.526+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.588+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.587+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:33:11.595+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.595+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:33:11.602+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.602+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:33:11.609+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T12:34:25.690+0100] {processor.py:186} INFO - Started process (PID=13782) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.691+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:34:25.691+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.691+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.693+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.693+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:34:25.695+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.759+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.759+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:34:25.767+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.767+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:34:25.774+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.774+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:34:25.781+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T12:35:44.121+0100] {processor.py:186} INFO - Started process (PID=13975) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.122+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:35:44.122+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.122+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.124+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.124+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:35:44.126+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.187+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.186+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:35:44.194+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.194+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:35:44.201+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.201+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:35:44.208+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:37:03.255+0100] {processor.py:186} INFO - Started process (PID=14180) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.255+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:37:03.256+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.256+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.257+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.257+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:37:03.259+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.327+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:37:03.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.330+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:37:03.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.337+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:37:03.348+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T12:38:19.181+0100] {processor.py:186} INFO - Started process (PID=14356) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.181+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:38:19.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.182+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.184+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.184+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:38:19.186+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.264+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.260+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:38:19.264+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.264+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:38:19.271+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.270+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:38:19.281+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.102 seconds
[2025-02-20T12:54:30.052+0100] {processor.py:186} INFO - Started process (PID=14531) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.053+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:54:30.053+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.053+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.054+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.054+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:54:30.057+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.123+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.119+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:54:30.123+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.123+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:54:30.130+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.130+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:54:30.139+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:56:08.780+0100] {processor.py:186} INFO - Started process (PID=14722) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.781+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:56:08.782+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.782+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.784+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.784+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:56:08.787+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.868+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.864+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:56:08.869+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.869+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:56:08.876+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.876+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:56:08.887+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.110 seconds
[2025-02-20T12:57:48.265+0100] {processor.py:186} INFO - Started process (PID=14916) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.266+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:57:48.266+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.266+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.268+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.268+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:57:48.271+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.344+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.340+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:57:48.344+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.344+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:57:48.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.353+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:57:48.363+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.100 seconds
[2025-02-20T12:59:18.705+0100] {processor.py:186} INFO - Started process (PID=15046) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.706+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:59:18.707+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.706+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.708+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.708+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:59:18.711+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.781+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.777+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:59:18.781+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.781+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:59:18.788+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.788+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:59:18.797+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T13:00:41.012+0100] {processor.py:186} INFO - Started process (PID=15174) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.013+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:00:41.013+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.013+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.015+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.015+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:00:41.018+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.085+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.081+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:00:41.085+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.085+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:00:41.092+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.092+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:00:41.102+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:02:00.554+0100] {processor.py:186} INFO - Started process (PID=15278) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.555+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:02:00.556+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.556+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.557+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.557+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:02:00.559+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.626+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.622+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:02:00.626+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.626+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:02:00.633+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.633+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:02:00.642+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T13:03:18.253+0100] {processor.py:186} INFO - Started process (PID=15376) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.254+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:03:18.254+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.254+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.255+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.255+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:03:18.258+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.321+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.320+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:03:18.321+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.321+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:03:18.327+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.327+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:03:18.336+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.084 seconds
[2025-02-20T13:07:33.144+0100] {processor.py:186} INFO - Started process (PID=15560) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.145+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:07:33.146+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.145+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.147+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.147+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:07:33.150+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.219+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.215+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:07:33.219+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.219+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:07:33.226+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.226+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:07:33.235+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T13:08:52.665+0100] {processor.py:186} INFO - Started process (PID=15777) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.665+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:08:52.666+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.666+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.668+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.668+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:08:52.671+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.744+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.740+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:08:52.745+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.745+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:08:52.752+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.751+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:08:52.762+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.100 seconds
[2025-02-20T13:10:17.951+0100] {processor.py:186} INFO - Started process (PID=15961) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:17.952+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:10:17.952+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:17.952+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:17.954+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:17.954+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:10:17.957+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:18.054+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.045+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:10:18.055+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.055+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:10:18.063+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.063+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:10:18.075+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.125 seconds
[2025-02-20T13:11:43.632+0100] {processor.py:186} INFO - Started process (PID=16079) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.633+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:11:43.633+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.633+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.635+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.635+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:11:43.637+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.710+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.705+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:11:43.710+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.710+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:11:43.717+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.717+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:11:43.727+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:13:10.544+0100] {processor.py:186} INFO - Started process (PID=16218) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.545+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:13:10.546+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.546+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.548+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.548+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:13:10.550+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.624+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.620+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:13:10.625+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.625+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:13:10.632+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.632+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:13:10.643+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T13:14:45.307+0100] {processor.py:186} INFO - Started process (PID=16356) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.308+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:14:45.308+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.308+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.310+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.310+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:14:45.313+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.381+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:14:45.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.385+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:14:45.392+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.392+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:14:45.401+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:16:08.682+0100] {processor.py:186} INFO - Started process (PID=16520) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.683+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:16:08.683+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.683+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.685+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:16:08.688+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.752+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:16:08.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.757+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:16:08.764+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.763+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:16:08.773+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T13:17:44.239+0100] {processor.py:186} INFO - Started process (PID=16730) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.239+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:17:44.240+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.240+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.241+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.241+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:17:44.244+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.309+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:17:44.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.313+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:17:44.320+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.320+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:17:44.329+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T13:19:18.638+0100] {processor.py:186} INFO - Started process (PID=16927) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.639+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:19:18.639+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.639+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.641+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.641+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:19:18.643+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.712+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.707+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:19:18.712+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.712+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:19:18.718+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.718+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:19:18.728+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T13:20:53.813+0100] {processor.py:186} INFO - Started process (PID=17029) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.814+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:20:53.815+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.815+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.816+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.816+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:20:53.819+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.886+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.882+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:20:53.887+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.886+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:20:53.893+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.893+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:20:53.903+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:22:17.345+0100] {processor.py:186} INFO - Started process (PID=17249) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.346+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:22:17.347+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.346+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.349+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.349+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:22:17.351+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.413+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.413+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:22:17.421+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.421+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:22:17.427+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.427+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:22:17.435+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:23:37.403+0100] {processor.py:186} INFO - Started process (PID=17392) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.404+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:23:37.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.404+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.406+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.406+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:23:37.409+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.480+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.480+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:23:37.489+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.488+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:23:37.497+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.497+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:23:37.505+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.103 seconds
[2025-02-20T13:24:55.009+0100] {processor.py:186} INFO - Started process (PID=17486) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.010+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:24:55.010+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.010+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.013+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.013+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:24:55.015+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.103+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.103+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:24:55.112+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.112+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:24:55.119+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.119+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:24:55.126+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.119 seconds
[2025-02-20T13:26:12.817+0100] {processor.py:186} INFO - Started process (PID=17592) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.818+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:26:12.818+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.818+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.820+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.820+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:26:12.822+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.883+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.882+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:26:12.890+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.890+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:26:12.897+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.897+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:26:12.904+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
