[2025-02-20T10:18:31.340+0100] {processor.py:186} INFO - Started process (PID=5359) to work on /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.341+0100] {processor.py:914} INFO - Processing file /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:18:31.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.342+0100] {dagbag.py:588} INFO - Filling up the DagBag from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.436+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.436+0100] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2025-02-20T10:18:31.533+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:18:31.645+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.644+0100] {override.py:1912} INFO - Created Permission View: can delete on DAG:example_workday_timetable
[2025-02-20T10:18:31.648+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.648+0100] {override.py:1912} INFO - Created Permission View: can edit on DAG:example_workday_timetable
[2025-02-20T10:18:31.651+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.651+0100] {override.py:1912} INFO - Created Permission View: can read on DAG:example_workday_timetable
[2025-02-20T10:18:31.654+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.654+0100] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.656+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.656+0100] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.658+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.657+0100] {override.py:1912} INFO - Created Permission View: can create on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.660+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.660+0100] {override.py:1912} INFO - Created Permission View: can read on DAG Run:example_workday_timetable
[2025-02-20T10:18:31.660+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.660+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:18:31.664+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.664+0100] {dag.py:3262} INFO - Creating ORM DAG for example_workday_timetable
[2025-02-20T10:18:31.686+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:18:31.686+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-02-20T10:18:31.694+0100] {processor.py:208} INFO - Processing /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py took 0.355 seconds
[2025-02-20T10:49:04.448+0100] {processor.py:186} INFO - Started process (PID=5990) to work on /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.448+0100] {processor.py:914} INFO - Processing file /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:49:04.449+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.449+0100] {dagbag.py:588} INFO - Filling up the DagBag from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.531+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.531+0100] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2025-02-20T10:49:04.617+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:49:04.702+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.701+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:49:04.725+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:49:04.725+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-02-20T10:49:04.732+0100] {processor.py:208} INFO - Processing /opt/anaconda3/lib/python3.12/site-packages/airflow/example_dags/example_workday_timetable.py took 0.285 seconds
[2025-02-20T10:52:09.612+0100] {processor.py:186} INFO - Started process (PID=6204) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.613+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:52:09.613+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.613+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.615+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.615+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:52:09.617+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:52:09.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.685+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:52:09.731+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.730+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:52:09.740+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:52:09.739+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:52:09.748+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.138 seconds
[2025-02-20T10:54:00.106+0100] {processor.py:186} INFO - Started process (PID=6464) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.107+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:54:00.107+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.107+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.109+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.109+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:54:00.112+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:54:00.174+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.174+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:54:00.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.182+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:54:00.189+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:54:00.189+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:54:00.196+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T10:55:15.824+0100] {processor.py:186} INFO - Started process (PID=6659) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.825+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:55:15.825+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.825+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.827+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.827+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:55:15.830+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:55:15.894+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.894+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:55:15.902+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.902+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:55:15.908+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:55:15.908+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:55:15.916+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T10:56:27.948+0100] {processor.py:186} INFO - Started process (PID=6782) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:27.948+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:56:27.949+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:27.949+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:27.951+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:27.951+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:56:27.953+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:56:28.014+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.014+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:56:28.022+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.022+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:56:28.028+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:56:28.028+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:56:28.035+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T10:57:55.649+0100] {processor.py:186} INFO - Started process (PID=6928) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.649+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:57:55.650+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.650+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.653+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.653+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:57:55.657+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:57:55.721+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.720+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:57:55.728+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.728+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:57:55.735+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:57:55.735+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:57:55.742+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T10:59:21.334+0100] {processor.py:186} INFO - Started process (PID=7061) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.335+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T10:59:21.335+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.335+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.337+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:59:21.340+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T10:59:21.403+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.403+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T10:59:21.411+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.411+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T10:59:21.418+0100] {logging_mixin.py:190} INFO - [2025-02-20T10:59:21.418+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T10:59:21.425+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:00:40.610+0100] {processor.py:186} INFO - Started process (PID=7269) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.611+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:00:40.612+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.611+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.613+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.613+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:00:40.615+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:00:40.677+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.677+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:00:40.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.685+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:00:40.691+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:00:40.691+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:00:40.698+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:01:52.466+0100] {processor.py:186} INFO - Started process (PID=7408) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.467+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:01:52.468+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.467+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.469+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.469+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:01:52.472+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:01:52.545+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.545+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:01:52.554+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.554+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:01:52.562+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:01:52.562+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:01:52.574+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.109 seconds
[2025-02-20T11:03:04.038+0100] {processor.py:186} INFO - Started process (PID=7548) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.039+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:03:04.040+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.039+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.042+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.041+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:03:04.044+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:03:04.116+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.114+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:03:04.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.181+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:03:04.254+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:03:04.254+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:03:04.276+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.239 seconds
[2025-02-20T11:04:14.070+0100] {processor.py:186} INFO - Started process (PID=7669) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.071+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:04:14.072+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.072+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.073+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.073+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:04:14.075+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:04:14.136+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.135+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:04:14.143+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.143+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:04:14.149+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:04:14.149+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:04:14.156+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:05:23.498+0100] {processor.py:186} INFO - Started process (PID=7827) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.499+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:05:23.499+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.499+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.501+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.501+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:05:23.503+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:05:23.564+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.564+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:05:23.572+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.572+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:05:23.579+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:05:23.579+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:05:23.586+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:06:33.872+0100] {processor.py:186} INFO - Started process (PID=8002) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.873+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:06:33.873+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.873+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.875+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.875+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:06:33.877+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:06:33.941+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.941+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:06:33.950+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.950+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:06:33.956+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:06:33.956+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:06:33.963+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:07:43.378+0100] {processor.py:186} INFO - Started process (PID=8147) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.378+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:07:43.379+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.379+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.381+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.380+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:07:43.383+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:07:43.444+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.444+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:07:43.452+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.452+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:07:43.458+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:07:43.458+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:07:43.465+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:08:52.830+0100] {processor.py:186} INFO - Started process (PID=8264) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.832+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:08:52.832+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.832+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.833+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.833+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:08:52.835+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:08:52.896+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.896+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:08:52.904+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.904+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:08:52.910+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:08:52.910+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:08:52.917+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:10:01.445+0100] {processor.py:186} INFO - Started process (PID=8370) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.445+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:10:01.446+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.446+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.447+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.447+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:10:01.449+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:10:01.511+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.511+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:10:01.519+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.519+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:10:01.525+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:10:01.525+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:10:01.532+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:11:13.350+0100] {processor.py:186} INFO - Started process (PID=8530) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.351+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:11:13.352+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.351+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.353+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:11:13.356+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:11:13.417+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.417+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:11:13.425+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.425+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:11:13.432+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:11:13.432+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:11:13.439+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:12:20.362+0100] {processor.py:186} INFO - Started process (PID=8623) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.363+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:12:20.363+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.363+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.365+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.365+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:12:20.368+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:12:20.428+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.427+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:12:20.435+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.435+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:12:20.442+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:12:20.442+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:12:20.448+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T11:13:29.324+0100] {processor.py:186} INFO - Started process (PID=8752) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.324+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:13:29.325+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.325+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.327+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.326+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:13:29.329+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:13:29.396+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.396+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:13:29.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.404+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:13:29.411+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:13:29.411+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:13:29.418+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T11:14:43.256+0100] {processor.py:186} INFO - Started process (PID=8885) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.257+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:14:43.257+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.257+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.259+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.259+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:14:43.261+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:14:43.322+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.322+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:14:43.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.330+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:14:43.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:14:43.337+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:14:43.346+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:15:56.316+0100] {processor.py:186} INFO - Started process (PID=8979) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.317+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:15:56.318+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.318+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.320+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.320+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:15:56.322+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:15:56.393+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.393+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:15:56.401+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.401+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:15:56.408+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:15:56.408+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:15:56.415+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T11:17:07.726+0100] {processor.py:186} INFO - Started process (PID=9181) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.727+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:17:07.727+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.727+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.729+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.729+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:17:07.732+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:17:07.793+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.793+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:17:07.801+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.800+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:17:07.807+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:17:07.807+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:17:07.814+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:18:20.720+0100] {processor.py:186} INFO - Started process (PID=9360) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.721+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:18:20.722+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.722+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.724+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.724+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:18:20.726+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:18:20.789+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.788+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:18:20.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.796+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:18:20.803+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:18:20.803+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:18:20.810+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:19:35.520+0100] {processor.py:186} INFO - Started process (PID=9549) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.520+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:19:35.521+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.521+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.522+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.522+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:19:35.524+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:19:35.587+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.587+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:19:35.595+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.595+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:19:35.601+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:19:35.601+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:19:35.608+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:20:49.838+0100] {processor.py:186} INFO - Started process (PID=9712) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.839+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:20:49.840+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.839+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.841+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.841+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:20:49.843+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:20:49.905+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.905+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:20:49.913+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.913+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:20:49.919+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:20:49.919+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:20:49.926+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:22:01.274+0100] {processor.py:186} INFO - Started process (PID=9810) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.275+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:22:01.275+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.275+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.277+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.277+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:22:01.279+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:22:01.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.341+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:22:01.350+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.350+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:22:01.357+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:22:01.357+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:22:01.365+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:23:16.482+0100] {processor.py:186} INFO - Started process (PID=9955) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.483+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:23:16.483+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.483+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.485+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.485+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:23:16.487+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:23:16.551+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.551+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:23:16.559+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.559+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:23:16.566+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:23:16.565+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:23:16.572+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:24:32.601+0100] {processor.py:186} INFO - Started process (PID=10094) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.602+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:24:32.603+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.603+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.604+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.604+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:24:32.607+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:24:32.669+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.669+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:24:32.677+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.677+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:24:32.683+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:24:32.683+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:24:32.689+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:25:46.273+0100] {processor.py:186} INFO - Started process (PID=10219) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.274+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:25:46.274+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.274+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.276+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.276+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:25:46.278+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:25:46.338+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.338+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:25:46.347+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.346+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:25:46.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:25:46.353+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:25:46.360+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:27:00.309+0100] {processor.py:186} INFO - Started process (PID=10395) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.310+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:27:00.310+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.310+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.312+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.312+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:27:00.314+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:27:00.375+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.375+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:27:00.383+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.382+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:27:00.389+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:27:00.389+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:27:00.396+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:28:14.790+0100] {processor.py:186} INFO - Started process (PID=10549) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.790+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:28:14.791+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.791+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.793+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.793+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:28:14.795+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:28:14.855+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.855+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:28:14.863+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.863+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:28:14.870+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:28:14.870+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:28:14.877+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:29:30.153+0100] {processor.py:186} INFO - Started process (PID=10762) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.154+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:29:30.154+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.154+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.156+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.156+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:29:30.158+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:29:30.220+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.220+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:29:30.228+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.228+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:29:30.234+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:29:30.234+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:29:30.242+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:30:43.312+0100] {processor.py:186} INFO - Started process (PID=10880) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.312+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:30:43.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.313+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.315+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.315+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:30:43.317+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:30:43.379+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.379+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:30:43.387+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.387+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:30:43.394+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:30:43.394+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:30:43.401+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T11:31:58.888+0100] {processor.py:186} INFO - Started process (PID=11018) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.889+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:31:58.889+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.889+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.891+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.891+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:31:58.893+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:31:58.953+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.953+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:31:58.964+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.964+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:31:58.970+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:31:58.970+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:31:58.977+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:33:10.468+0100] {processor.py:186} INFO - Started process (PID=11112) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.469+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:33:10.469+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.469+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.471+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.471+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:33:10.473+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:33:10.535+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.535+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:33:10.543+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.543+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:33:10.549+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:33:10.549+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:33:10.556+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:34:24.664+0100] {processor.py:186} INFO - Started process (PID=11233) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.665+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:34:24.665+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.665+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.667+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.667+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:34:24.670+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:34:24.732+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.732+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:34:24.740+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.740+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:34:24.746+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:34:24.746+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:34:24.753+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T11:35:37.965+0100] {processor.py:186} INFO - Started process (PID=11353) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:37.966+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:35:37.966+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:37.966+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:37.968+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:37.968+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:35:37.971+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:35:38.034+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.034+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:35:38.042+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.042+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:35:38.049+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:35:38.049+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:35:38.056+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T11:36:55.842+0100] {processor.py:186} INFO - Started process (PID=11517) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.843+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:36:55.844+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.844+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.845+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.845+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:36:55.847+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:36:55.911+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.911+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:36:55.919+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.919+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:36:55.925+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:36:55.925+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:36:55.932+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T11:38:12.757+0100] {processor.py:186} INFO - Started process (PID=11643) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.757+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:38:12.758+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.758+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.760+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.760+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:38:12.762+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:38:12.832+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.832+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:38:12.841+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.841+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:38:12.849+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:38:12.848+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:38:12.856+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T11:39:23.127+0100] {processor.py:186} INFO - Started process (PID=11744) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.128+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:39:23.128+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.128+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.130+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.130+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:39:23.132+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:39:23.193+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.193+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:39:23.201+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.201+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:39:23.207+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:39:23.207+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:39:23.214+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T11:40:36.067+0100] {processor.py:186} INFO - Started process (PID=11846) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.068+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T11:40:36.069+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.069+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.071+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.071+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:40:36.077+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T11:40:36.163+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.163+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T11:40:36.174+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.174+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T11:40:36.184+0100] {logging_mixin.py:190} INFO - [2025-02-20T11:40:36.184+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T11:40:36.193+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.127 seconds
[2025-02-20T12:18:49.100+0100] {processor.py:186} INFO - Started process (PID=11984) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.100+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:18:49.101+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.101+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.102+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.102+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:18:49.105+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:18:49.170+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.170+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:18:49.178+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.178+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:18:49.185+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:18:49.185+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:18:49.192+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T12:20:31.138+0100] {processor.py:186} INFO - Started process (PID=12135) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.138+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:20:31.139+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.139+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.140+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.140+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:20:31.143+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:20:31.204+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.204+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:20:31.212+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.212+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:20:31.218+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:20:31.218+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:20:31.225+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T12:21:51.843+0100] {processor.py:186} INFO - Started process (PID=12248) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.844+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:21:51.844+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.844+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.846+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.846+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:21:51.848+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:21:51.908+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.908+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:21:51.916+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.916+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:21:51.923+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:21:51.923+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:21:51.930+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:23:10.018+0100] {processor.py:186} INFO - Started process (PID=12408) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.020+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:23:10.021+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.021+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.024+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.024+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:23:10.030+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:23:10.121+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.121+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:23:10.132+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.132+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:23:10.139+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:23:10.139+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:23:10.147+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.131 seconds
[2025-02-20T12:24:25.325+0100] {processor.py:186} INFO - Started process (PID=12546) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.326+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:24:25.326+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.326+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.328+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.328+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:24:25.331+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:24:25.396+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.396+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:24:25.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.404+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:24:25.410+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:24:25.410+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:24:25.417+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T12:25:38.232+0100] {processor.py:186} INFO - Started process (PID=12663) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.233+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:25:38.239+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.239+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.241+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.241+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:25:38.244+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:25:38.326+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.326+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:25:38.335+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.335+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:25:38.342+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:25:38.342+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:25:38.350+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.119 seconds
[2025-02-20T12:26:53.715+0100] {processor.py:186} INFO - Started process (PID=12839) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.715+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:26:53.716+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.716+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.718+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.718+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:26:53.720+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:26:53.782+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.782+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:26:53.790+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.790+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:26:53.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:26:53.796+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:26:53.803+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T12:28:09.522+0100] {processor.py:186} INFO - Started process (PID=12993) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.523+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:28:09.523+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.523+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.526+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.526+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:28:09.528+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:28:09.596+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.596+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:28:09.604+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.604+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:28:09.611+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:28:09.611+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:28:09.618+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.099 seconds
[2025-02-20T12:29:23.382+0100] {processor.py:186} INFO - Started process (PID=13133) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.383+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:29:23.383+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.383+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.385+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:29:23.387+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:29:23.456+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.456+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:29:23.464+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.464+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:29:23.471+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:29:23.471+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:29:23.478+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T12:30:34.756+0100] {processor.py:186} INFO - Started process (PID=13286) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.757+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:30:34.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.757+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.759+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.759+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:30:34.761+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:30:34.836+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.834+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:30:34.855+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.855+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:30:34.862+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:30:34.862+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:30:34.870+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.115 seconds
[2025-02-20T12:31:52.640+0100] {processor.py:186} INFO - Started process (PID=13466) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.641+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:31:52.641+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.641+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.643+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.643+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:31:52.645+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:31:52.706+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.706+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:31:52.715+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.714+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:31:52.721+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:31:52.721+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:31:52.728+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T12:33:11.521+0100] {processor.py:186} INFO - Started process (PID=13639) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.522+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:33:11.522+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.522+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.524+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.524+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:33:11.526+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:33:11.588+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.587+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:33:11.595+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.595+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:33:11.602+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:33:11.602+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:33:11.609+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T12:34:25.690+0100] {processor.py:186} INFO - Started process (PID=13782) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.691+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:34:25.691+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.691+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.693+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.693+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:34:25.695+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:34:25.759+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.759+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:34:25.767+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.767+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:34:25.774+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:34:25.774+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:34:25.781+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T12:35:44.121+0100] {processor.py:186} INFO - Started process (PID=13975) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.122+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:35:44.122+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.122+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.124+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.124+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:35:44.126+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:35:44.187+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.186+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:35:44.194+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.194+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:35:44.201+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:35:44.201+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:35:44.208+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:37:03.255+0100] {processor.py:186} INFO - Started process (PID=14180) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.255+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:37:03.256+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.256+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.257+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.257+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:37:03.259+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:37:03.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.327+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:37:03.330+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.330+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:37:03.337+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:37:03.337+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:37:03.348+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T12:38:19.181+0100] {processor.py:186} INFO - Started process (PID=14356) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.181+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:38:19.182+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.182+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.184+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.184+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:38:19.186+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:38:19.264+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.260+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:38:19.264+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.264+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:38:19.271+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:38:19.270+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:38:19.281+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.102 seconds
[2025-02-20T12:54:30.052+0100] {processor.py:186} INFO - Started process (PID=14531) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.053+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:54:30.053+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.053+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.054+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.054+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:54:30.057+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:54:30.123+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.119+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:54:30.123+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.123+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:54:30.130+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:54:30.130+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:54:30.139+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T12:56:08.780+0100] {processor.py:186} INFO - Started process (PID=14722) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.781+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:56:08.782+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.782+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.784+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.784+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:56:08.787+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:56:08.868+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.864+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:56:08.869+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.869+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:56:08.876+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:56:08.876+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:56:08.887+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.110 seconds
[2025-02-20T12:57:48.265+0100] {processor.py:186} INFO - Started process (PID=14916) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.266+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:57:48.266+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.266+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.268+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.268+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:57:48.271+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:57:48.344+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.340+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:57:48.344+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.344+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:57:48.353+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:57:48.353+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:57:48.363+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.100 seconds
[2025-02-20T12:59:18.705+0100] {processor.py:186} INFO - Started process (PID=15046) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.706+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T12:59:18.707+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.706+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.708+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.708+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T12:59:18.711+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T12:59:18.781+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.777+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T12:59:18.781+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.781+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T12:59:18.788+0100] {logging_mixin.py:190} INFO - [2025-02-20T12:59:18.788+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T12:59:18.797+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T13:00:41.012+0100] {processor.py:186} INFO - Started process (PID=15174) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.013+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:00:41.013+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.013+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.015+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.015+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:00:41.018+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:00:41.085+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.081+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:00:41.085+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.085+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:00:41.092+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:00:41.092+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:00:41.102+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:02:00.554+0100] {processor.py:186} INFO - Started process (PID=15278) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.555+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:02:00.556+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.556+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.557+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.557+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:02:00.559+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:02:00.626+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.622+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:02:00.626+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.626+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:02:00.633+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:02:00.633+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:02:00.642+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T13:03:18.253+0100] {processor.py:186} INFO - Started process (PID=15376) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.254+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:03:18.254+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.254+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.255+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.255+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:03:18.258+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:03:18.321+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.320+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:03:18.321+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.321+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:03:18.327+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:03:18.327+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:03:18.336+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.084 seconds
[2025-02-20T13:07:33.144+0100] {processor.py:186} INFO - Started process (PID=15560) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.145+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:07:33.146+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.145+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.147+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.147+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:07:33.150+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:07:33.219+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.215+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:07:33.219+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.219+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:07:33.226+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:07:33.226+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:07:33.235+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T13:08:52.665+0100] {processor.py:186} INFO - Started process (PID=15777) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.665+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:08:52.666+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.666+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.668+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.668+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:08:52.671+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:08:52.744+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.740+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:08:52.745+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.745+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:08:52.752+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:08:52.751+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:08:52.762+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.100 seconds
[2025-02-20T13:10:17.951+0100] {processor.py:186} INFO - Started process (PID=15961) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:17.952+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:10:17.952+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:17.952+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:17.954+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:17.954+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:10:17.957+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:10:18.054+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.045+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:10:18.055+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.055+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:10:18.063+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:10:18.063+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:10:18.075+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.125 seconds
[2025-02-20T13:11:43.632+0100] {processor.py:186} INFO - Started process (PID=16079) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.633+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:11:43.633+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.633+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.635+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.635+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:11:43.637+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:11:43.710+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.705+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:11:43.710+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.710+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:11:43.717+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:11:43.717+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:11:43.727+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:13:10.544+0100] {processor.py:186} INFO - Started process (PID=16218) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.545+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:13:10.546+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.546+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.548+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.548+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:13:10.550+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:13:10.624+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.620+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:13:10.625+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.625+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:13:10.632+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:13:10.632+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:13:10.643+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.101 seconds
[2025-02-20T13:14:45.307+0100] {processor.py:186} INFO - Started process (PID=16356) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.308+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:14:45.308+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.308+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.310+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.310+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:14:45.313+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:14:45.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.381+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:14:45.385+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.385+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:14:45.392+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:14:45.392+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:14:45.401+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:16:08.682+0100] {processor.py:186} INFO - Started process (PID=16520) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.683+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:16:08.683+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.683+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.685+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.685+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:16:08.688+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:16:08.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.752+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:16:08.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.757+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:16:08.764+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:16:08.763+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:16:08.773+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T13:17:44.239+0100] {processor.py:186} INFO - Started process (PID=16730) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.239+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:17:44.240+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.240+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.241+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.241+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:17:44.244+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:17:44.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.309+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:17:44.313+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.313+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:17:44.320+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:17:44.320+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:17:44.329+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T13:19:18.638+0100] {processor.py:186} INFO - Started process (PID=16927) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.639+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:19:18.639+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.639+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.641+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.641+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:19:18.643+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:19:18.712+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.707+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:19:18.712+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.712+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:19:18.718+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:19:18.718+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:19:18.728+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T13:20:53.813+0100] {processor.py:186} INFO - Started process (PID=17029) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.814+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:20:53.815+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.815+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.816+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.816+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:20:53.819+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:20:53.886+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.882+0100] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
  File "<string>", line 4, in __init__
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
  File "/Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-02-20T13:20:53.887+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.886+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:20:53.893+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:20:53.893+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:20:53.903+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:22:17.345+0100] {processor.py:186} INFO - Started process (PID=17249) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.346+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:22:17.347+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.346+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.349+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.349+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:22:17.351+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:22:17.413+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.413+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:22:17.421+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.421+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:22:17.427+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:22:17.427+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:22:17.435+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:23:37.403+0100] {processor.py:186} INFO - Started process (PID=17392) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.404+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:23:37.404+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.404+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.406+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.406+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:23:37.409+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:23:37.480+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.480+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:23:37.489+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.488+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:23:37.497+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:23:37.497+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:23:37.505+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.103 seconds
[2025-02-20T13:24:55.009+0100] {processor.py:186} INFO - Started process (PID=17486) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.010+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:24:55.010+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.010+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.013+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.013+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:24:55.015+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:24:55.103+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.103+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:24:55.112+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.112+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:24:55.119+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:24:55.119+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:24:55.126+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.119 seconds
[2025-02-20T13:26:12.817+0100] {processor.py:186} INFO - Started process (PID=17592) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.818+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:26:12.818+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.818+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.820+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.820+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:26:12.822+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:26:12.883+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.882+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:26:12.890+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.890+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:26:12.897+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:26:12.897+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:26:12.904+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T13:27:31.788+0100] {processor.py:186} INFO - Started process (PID=17805) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:27:31.789+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:27:31.790+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:27:31.789+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:27:31.791+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:27:31.791+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:27:31.794+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:27:31.855+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:27:31.855+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:27:31.867+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:27:31.867+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:27:31.874+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:27:31.873+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:27:31.880+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T13:28:52.793+0100] {processor.py:186} INFO - Started process (PID=17960) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:28:52.793+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:28:52.794+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:28:52.794+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:28:52.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:28:52.796+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:28:52.799+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:28:52.860+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:28:52.860+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:28:52.868+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:28:52.868+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:28:52.875+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:28:52.875+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:28:52.882+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:30:09.663+0100] {processor.py:186} INFO - Started process (PID=18061) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:30:09.663+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:30:09.664+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:30:09.664+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:30:09.666+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:30:09.666+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:30:09.670+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:30:09.736+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:30:09.736+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:30:09.744+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:30:09.743+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:30:09.750+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:30:09.750+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:30:09.757+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:31:29.703+0100] {processor.py:186} INFO - Started process (PID=18166) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:31:29.704+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:31:29.704+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:31:29.704+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:31:29.706+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:31:29.705+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:31:29.708+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:31:29.769+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:31:29.769+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:31:29.777+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:31:29.777+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:31:29.784+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:31:29.784+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:31:29.790+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T13:32:49.449+0100] {processor.py:186} INFO - Started process (PID=18258) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:32:49.450+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:32:49.450+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:32:49.450+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:32:49.452+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:32:49.452+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:32:49.454+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:32:49.518+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:32:49.518+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:32:49.526+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:32:49.525+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:32:49.534+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:32:49.534+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:32:49.541+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T13:34:11.650+0100] {processor.py:186} INFO - Started process (PID=18350) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:34:11.651+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:34:11.652+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:34:11.652+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:34:11.654+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:34:11.654+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:34:11.656+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:34:11.721+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:34:11.721+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:34:11.729+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:34:11.729+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:34:11.738+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:34:11.738+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:34:11.746+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T13:35:32.253+0100] {processor.py:186} INFO - Started process (PID=18529) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:35:32.254+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:35:32.254+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:35:32.254+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:35:32.256+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:35:32.256+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:35:32.258+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:35:32.326+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:35:32.326+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:35:32.334+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:35:32.334+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:35:32.340+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:35:32.340+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:35:32.348+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:36:56.239+0100] {processor.py:186} INFO - Started process (PID=18752) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:36:56.240+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:36:56.240+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:36:56.240+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:36:56.242+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:36:56.242+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:36:56.245+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:36:56.316+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:36:56.316+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:36:56.325+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:36:56.325+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:36:56.332+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:36:56.331+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:36:56.339+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.102 seconds
[2025-02-20T13:38:13.101+0100] {processor.py:186} INFO - Started process (PID=18930) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:38:13.102+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:38:13.102+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:38:13.102+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:38:13.104+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:38:13.104+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:38:13.106+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:38:13.171+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:38:13.171+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:38:13.180+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:38:13.180+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:38:13.187+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:38:13.187+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:38:13.195+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:39:35.058+0100] {processor.py:186} INFO - Started process (PID=19182) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:39:35.058+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:39:35.059+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:39:35.059+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:39:35.060+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:39:35.060+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:39:35.063+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:39:35.123+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:39:35.123+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:39:35.131+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:39:35.131+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:39:35.138+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:39:35.137+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:39:35.144+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.088 seconds
[2025-02-20T13:40:56.194+0100] {processor.py:186} INFO - Started process (PID=19441) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:40:56.194+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:40:56.195+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:40:56.195+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:40:56.197+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:40:56.197+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:40:56.200+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:40:56.274+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:40:56.273+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:40:56.284+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:40:56.283+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:40:56.291+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:40:56.291+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:40:56.300+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.108 seconds
[2025-02-20T13:42:23.274+0100] {processor.py:186} INFO - Started process (PID=19559) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:42:23.276+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:42:23.276+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:42:23.276+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:42:23.279+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:42:23.279+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:42:23.282+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:42:23.344+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:42:23.344+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:42:23.352+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:42:23.352+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:42:23.359+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:42:23.359+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:42:23.366+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.097 seconds
[2025-02-20T13:43:52.345+0100] {processor.py:186} INFO - Started process (PID=19764) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:43:52.346+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:43:52.346+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:43:52.346+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:43:52.348+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:43:52.348+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:43:52.350+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:43:52.414+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:43:52.414+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:43:52.423+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:43:52.423+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:43:52.431+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:43:52.431+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:43:52.439+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T13:45:19.111+0100] {processor.py:186} INFO - Started process (PID=20037) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:45:19.112+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:45:19.112+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:45:19.112+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:45:19.114+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:45:19.114+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:45:19.116+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:45:19.190+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:45:19.189+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:45:19.199+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:45:19.199+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:45:19.206+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:45:19.206+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:45:19.221+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.112 seconds
[2025-02-20T13:46:49.522+0100] {processor.py:186} INFO - Started process (PID=20334) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:46:49.528+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:46:49.529+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:46:49.529+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:46:49.531+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:46:49.531+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:46:49.533+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:46:49.599+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:46:49.599+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:46:49.607+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:46:49.607+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:46:49.613+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:46:49.613+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:46:49.620+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.100 seconds
[2025-02-20T13:48:21.714+0100] {processor.py:186} INFO - Started process (PID=20612) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:48:21.715+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:48:21.715+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:48:21.715+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:48:21.717+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:48:21.717+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:48:21.720+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:48:21.781+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:48:21.781+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:48:21.789+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:48:21.789+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:48:21.795+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:48:21.795+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:48:21.802+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T13:49:46.409+0100] {processor.py:186} INFO - Started process (PID=20765) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:49:46.409+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:49:46.410+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:49:46.410+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:49:46.412+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:49:46.411+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:49:46.414+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:49:46.479+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:49:46.479+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:49:46.487+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:49:46.487+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:49:46.493+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:49:46.493+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:49:46.501+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.094 seconds
[2025-02-20T13:51:16.735+0100] {processor.py:186} INFO - Started process (PID=20928) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:51:16.736+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:51:16.736+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:51:16.736+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:51:16.738+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:51:16.738+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:51:16.741+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:51:16.809+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:51:16.809+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:51:16.818+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:51:16.818+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:51:16.825+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:51:16.825+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:51:16.832+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.099 seconds
[2025-02-20T13:52:43.396+0100] {processor.py:186} INFO - Started process (PID=21029) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:52:43.397+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:52:43.398+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:52:43.397+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:52:43.399+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:52:43.399+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:52:43.402+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:52:43.464+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:52:43.464+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:52:43.472+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:52:43.472+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:52:43.478+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:52:43.478+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:52:43.485+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T13:54:10.048+0100] {processor.py:186} INFO - Started process (PID=21189) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:54:10.049+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:54:10.049+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:54:10.049+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:54:10.051+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:54:10.051+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:54:10.054+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:54:10.116+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:54:10.115+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:54:10.124+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:54:10.123+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:54:10.130+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:54:10.130+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:54:10.137+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.090 seconds
[2025-02-20T13:55:34.055+0100] {processor.py:186} INFO - Started process (PID=21283) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:55:34.056+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:55:34.056+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:55:34.056+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:55:34.058+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:55:34.058+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:55:34.061+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:55:34.127+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:55:34.127+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:55:34.135+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:55:34.135+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:55:34.142+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:55:34.142+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:55:34.151+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T13:57:04.163+0100] {processor.py:186} INFO - Started process (PID=21397) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:57:04.164+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:57:04.165+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:57:04.164+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:57:04.167+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:57:04.166+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:57:04.169+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:57:04.231+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:57:04.231+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:57:04.240+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:57:04.239+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:57:04.246+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:57:04.246+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:57:04.253+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T13:58:33.064+0100] {processor.py:186} INFO - Started process (PID=21529) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:58:33.065+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:58:33.065+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:58:33.065+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:58:33.067+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:58:33.067+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:58:33.069+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:58:33.131+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:58:33.131+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:58:33.138+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:58:33.138+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:58:33.145+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:58:33.145+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:58:33.152+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T13:59:57.168+0100] {processor.py:186} INFO - Started process (PID=21695) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:59:57.169+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T13:59:57.169+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:59:57.169+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:59:57.171+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:59:57.171+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:59:57.173+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T13:59:57.236+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:59:57.236+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T13:59:57.245+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:59:57.244+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T13:59:57.253+0100] {logging_mixin.py:190} INFO - [2025-02-20T13:59:57.253+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T13:59:57.262+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.096 seconds
[2025-02-20T14:01:26.506+0100] {processor.py:186} INFO - Started process (PID=21983) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:01:26.507+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:01:26.507+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:01:26.507+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:01:26.511+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:01:26.510+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:01:26.514+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:01:26.625+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:01:26.625+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:01:26.635+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:01:26.635+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:01:26.647+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:01:26.647+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:01:26.659+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.157 seconds
[2025-02-20T14:02:57.498+0100] {processor.py:186} INFO - Started process (PID=22151) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:02:57.499+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:02:57.499+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:02:57.499+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:02:57.501+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:02:57.501+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:02:57.503+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:02:57.565+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:02:57.565+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:02:57.573+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:02:57.573+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:02:57.579+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:02:57.579+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:02:57.586+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T14:04:24.794+0100] {processor.py:186} INFO - Started process (PID=22281) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:04:24.795+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:04:24.796+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:04:24.795+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:04:24.797+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:04:24.797+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:04:24.799+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:04:24.862+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:04:24.862+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:04:24.877+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:04:24.877+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:04:24.884+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:04:24.884+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:04:24.891+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T14:05:52.427+0100] {processor.py:186} INFO - Started process (PID=22492) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:05:52.428+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:05:52.428+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:05:52.428+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:05:52.430+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:05:52.430+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:05:52.432+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:05:52.496+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:05:52.496+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:05:52.504+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:05:52.504+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:05:52.511+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:05:52.511+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:05:52.518+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.093 seconds
[2025-02-20T14:07:24.089+0100] {processor.py:186} INFO - Started process (PID=22678) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:07:24.090+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:07:24.090+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:07:24.090+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:07:24.092+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:07:24.092+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:07:24.094+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:07:24.157+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:07:24.157+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:07:24.165+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:07:24.165+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:07:24.172+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:07:24.172+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:07:24.179+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T14:08:55.637+0100] {processor.py:186} INFO - Started process (PID=22867) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:08:55.637+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:08:55.638+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:08:55.638+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:08:55.639+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:08:55.639+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:08:55.642+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:08:55.704+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:08:55.704+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:08:55.713+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:08:55.712+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:08:55.719+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:08:55.719+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:08:55.726+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.091 seconds
[2025-02-20T14:10:24.753+0100] {processor.py:186} INFO - Started process (PID=23044) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:10:24.754+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:10:24.755+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:10:24.755+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:10:24.757+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:10:24.757+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:10:24.759+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:10:24.830+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:10:24.830+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:10:24.839+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:10:24.839+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:10:24.848+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:10:24.848+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:10:24.864+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.113 seconds
[2025-02-20T14:11:51.615+0100] {processor.py:186} INFO - Started process (PID=23233) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:11:51.616+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:11:51.616+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:11:51.616+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:11:51.618+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:11:51.618+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:11:51.620+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:11:51.684+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:11:51.684+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:11:51.692+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:11:51.691+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:11:51.699+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:11:51.698+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:11:51.705+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.092 seconds
[2025-02-20T14:13:24.767+0100] {processor.py:186} INFO - Started process (PID=23456) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:13:24.768+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:13:24.769+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:13:24.768+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:13:24.770+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:13:24.770+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:13:24.772+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:13:24.832+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:13:24.832+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:13:24.841+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:13:24.840+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:13:24.852+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:13:24.852+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:13:24.863+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.098 seconds
[2025-02-20T14:14:55.688+0100] {processor.py:186} INFO - Started process (PID=23621) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:14:55.689+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:14:55.690+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:14:55.689+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:14:55.691+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:14:55.691+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:14:55.693+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:14:55.755+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:14:55.755+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:14:55.763+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:14:55.763+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:14:55.769+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:14:55.769+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:14:55.776+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.089 seconds
[2025-02-20T14:16:21.828+0100] {processor.py:186} INFO - Started process (PID=23722) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:16:21.829+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:16:21.830+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:16:21.829+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:16:21.831+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:16:21.831+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:16:21.834+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:16:21.921+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:16:21.921+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:16:21.932+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:16:21.932+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:16:21.939+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:16:21.939+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:16:21.946+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.119 seconds
[2025-02-20T14:19:17.390+0100] {processor.py:186} INFO - Started process (PID=23861) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:19:17.390+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:19:17.391+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:19:17.391+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:19:17.392+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:19:17.392+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:19:17.395+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:19:17.463+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:19:17.462+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:19:17.471+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:19:17.471+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:19:17.478+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:19:17.478+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:19:17.485+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.097 seconds
[2025-02-20T14:20:42.861+0100] {processor.py:186} INFO - Started process (PID=23957) to work on /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:20:42.862+0100] {processor.py:914} INFO - Processing file /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-02-20T14:20:42.863+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:20:42.863+0100] {dagbag.py:588} INFO - Filling up the DagBag from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:20:42.865+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:20:42.865+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:20:42.867+0100] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-02-20T14:20:42.932+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:20:42.932+0100] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2025-02-20T14:20:42.940+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:20:42.940+0100] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-20T14:20:42.947+0100] {logging_mixin.py:190} INFO - [2025-02-20T14:20:42.947+0100] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-01 00:00:00+00:00, run_after=2021-01-02 00:00:00+00:00
[2025-02-20T14:20:42.954+0100] {processor.py:208} INFO - Processing /Users/ajlakorman/Desktop/Data-Mining-Projects/Apache_Airflow/venv/lib/python3.10/site-packages/airflow/example_dags/example_workday_timetable.py took 0.095 seconds
